{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b32b8840",
   "metadata": {},
   "source": [
    "# Creating Synthetic Experts with Generative AI\n",
    "> ## Prediction with Fine-Tuned Model  \n",
    "*QuickStart* for individual Tweets\n",
    "  \n",
    "Version 1.0   \n",
    "Date: September 2, 2023    \n",
    "Author: Daniel M. Ringel    \n",
    "Contact: dmr@unc.edu\n",
    "\n",
    "*Daniel M. Ringel, Creating Synthetic Experts with Generative Artificial Intelligence (July 15, 2023).  \n",
    "Available at SSRN: https://papers.ssrn.com/abstract_id=4542949*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09215d3f",
   "metadata": {},
   "source": [
    "#### Requirements\n",
    "- PyTorch\n",
    "- BeautifulSoup\n",
    "- Huggingfaces transformers\n",
    "- Warnings and regular expressions (re)\n",
    "\n",
    "##### Apple M1/M2 GPU MPS Requirements (Optional)\n",
    "> See Python Notebook: [Setup-MacBook-M2-Pytorch-TensorFlow-Apr2023.ipynb](https://github.com/dringel/Synthetic-Experts)  \n",
    "\n",
    "- Mac computer with Apple silicon GPU\n",
    "- macOS 12.3 or later\n",
    "- Python 3.7 or later\n",
    "- Xcode command-line tools: xcode-select --install\n",
    "\n",
    "##### If you have no GPU available, the code falls back to your CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50847430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd, numpy as np, warnings, torch, re\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "938433fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def clean_and_parse_tweet(tweet):\n",
    "    tweet = re.sub(r\"https?://\\S+|www\\.\\S+\", \" URL \", tweet)\n",
    "    parsed = BeautifulSoup(tweet, \"html.parser\").get_text() if \"filename\" not in str(BeautifulSoup(tweet, \"html.parser\")) else None\n",
    "    return re.sub(r\" +\", \" \", re.sub(r'^[.:]+', '', re.sub(r\"\\\\n+|\\n+\", \" \", parsed or tweet)).strip()) if parsed else None\n",
    "\n",
    "def predict_tweet(tweet, model, tokenizer, device, threshold=0.5):\n",
    "    inputs = tokenizer(tweet, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
    "    probs = torch.sigmoid(model(**inputs).logits).detach().cpu().numpy()[0]\n",
    "    return probs, [id2label[i] for i, p in enumerate(probs) if id2label[i] in {'Product', 'Place', 'Price', 'Promotion'} and p >= threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7ff5871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "device = \"mps\" if \"backends\" in dir(torch) and hasattr(torch.backends, 'mps') and torch.backends.mps.is_built() and torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "synxp = \"dmr76/mmx_classifier_microblog_ENv02\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(synxp).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(synxp)\n",
    "id2label = model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cbb47f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---->>> Define your Tweet  <<<----\n",
    "tweet = \"Best cushioning ever!!! ðŸ¤—ðŸ¤—ðŸ¤—  my zoom vomeros are the bombðŸƒðŸ½â€â™€ï¸ðŸ’¨!!!  \\n @nike #run #training https://randomurl.ai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a604d1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Product'] [0.9948836  0.01391613 0.00593502 0.01573174]\n"
     ]
    }
   ],
   "source": [
    "# Clean and Predict\n",
    "cleaned_tweet = clean_and_parse_tweet(tweet)\n",
    "probs, labels = predict_tweet(cleaned_tweet, model, tokenizer, device)\n",
    "\n",
    "# Print Labels and Probabilities\n",
    "print(labels, probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
